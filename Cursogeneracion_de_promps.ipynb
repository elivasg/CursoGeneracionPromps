{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQWWA80O/M4GGi2Ro8djCl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elivasg/CursoGeneracionPromps/blob/main/Cursogeneracion_de_promps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjkphsH5Q4lO",
        "outputId": "e2a0c7d6-f411-4376-c995-b00b32f75a73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'cells': [{'cell_type': 'markdown',\n",
              "    'id': 'f291e06b-8057-4154-bb4b-14d7f5ea3cc7',\n",
              "    'metadata': {},\n",
              "    'source': ['                                                  Trabajo Final\\n',\n",
              "     '                                                    Entrega 2\\n',\n",
              "     '                                      \"Promps Actas de reuniones al instante\"\\n',\n",
              "     '                                                 \\\\Idea alquimica\\n',\n",
              "     '                                            \\\\Elizabeth Vasquez Gomez\\n',\n",
              "     '                                            \\\\Comisión 84185\\n',\n",
              "     '\\n',\n",
              "     'Presentacion del problema: Se desea generar a través de herramientas de inteligencia artificial , una solución donde se pueda ingresar información clave de la reunión y este genere un informe estructurado y oficial sobre los temas de la reunión, decisiones y Compomisos\\n',\n",
              "     '\\n',\n",
              "     'Contenido\\n',\n",
              "     '\\n',\n",
              "     '1- Descripcion 2- Objetivos 3- Metodología 4- Herramientas 5- Implementación\\n',\n",
              "     '\\n',\n",
              "     'Descripcion\\n',\n",
              "     'El primer prompt genera un informe sobre una reunion a partir de los datos ingresador  por el usuario.\\n',\n",
              "     'En el segundo paso el usuario la lista de compromisos.\\n',\n",
              "     'En el tercer paso se genera una imagen inforgrafica como parte del acta con la informacion de la reunion.\\n',\n",
              "     '\\n',\n",
              "     'Objetivos: Tener información de todas las decisiones y temas hablados en las reuniones de un proyecto de software de forma automatica.\\n',\n",
              "     '\\n',\n",
              "     'Metodología: Utilizar GPT-3.5 para realizar el resumen.\\n',\n",
              "     '\\n',\n",
              "     'Herramientas  Python OpenAI GPT-3.5-turbo y de imagen.\\n',\n",
              "     'La imagen generada se guarda en una sub carpeta de la misma ubicación del repositorio.']}]},)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"id\": \"f291e06b-8057-4154-bb4b-14d7f5ea3cc7\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"                                                  Trabajo Final\\n\",\n",
        "    \"                                                    Entrega 2\\n\",\n",
        "    \"                                      \\\"Promps Actas de reuniones al instante\\\"\\n\",\n",
        "    \"                                                 \\Idea alquimica\\n\",\n",
        "    \"                                            \\Elizabeth Vasquez Gomez\\n\",\n",
        "    \"                                            \\Comisión 84185\\n\",\n",
        "    \"\\n\",\n",
        "    \"Presentacion del problema: Se desea generar a través de herramientas de inteligencia artificial , una solución donde se pueda ingresar información clave de la reunión y este genere un informe estructurado y oficial sobre los temas de la reunión, decisiones y Compomisos\\n\",\n",
        "    \"\\n\",\n",
        "    \"Contenido\\n\",\n",
        "    \"\\n\",\n",
        "    \"1- Descripcion 2- Objetivos 3- Metodología 4- Herramientas 5- Implementación\\n\",\n",
        "    \"\\n\",\n",
        "    \"Descripcion\\n\",\n",
        "    \"El primer prompt genera un informe sobre una reunion a partir de los datos ingresador  por el usuario.\\n\",\n",
        "    \"En el segundo paso el usuario la lista de compromisos.\\n\",\n",
        "    \"En el tercer paso se genera una imagen inforgrafica como parte del acta con la informacion de la reunion.\\n\",\n",
        "    \"\\n\",\n",
        "    \"Objetivos: Tener información de todas las decisiones y temas hablados en las reuniones de un proyecto de software de forma automatica.\\n\",\n",
        "    \"\\n\",\n",
        "    \"Metodología: Utilizar GPT-3.5 para realizar el resumen.\\n\",\n",
        "    \"\\n\",\n",
        "    \"Herramientas  Python OpenAI GPT-3.5-turbo y de imagen.\\n\",\n",
        "    \"La imagen generada se guarda en una sub carpeta de la misma ubicación del repositorio.\"\n",
        "   ]\n",
        "  }\n",
        "  ]\n",
        " },"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar compoentes requeridos\n",
        "import sys\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "import requests\n",
        "import os\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import csv\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "iPJzUcOuTYHf"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKO817jidI3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4QLw1z5bdJaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "d5iT5Ew5dsHv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creacion de contexto\n",
        "context = \"Eres la responsable de generar las notas, acuerdos y compromisos que se hacen en las reuniones de un equipo de desarrollo de software donde es muy importante que todo quede claro\"\n",
        "\n",
        "# saludo\n",
        "class AsistenteActas:\n",
        "    def __init__(self, nombre, acta):\n",
        "        self.nombre = nombre\n",
        "        self.acta = acta\n",
        "\n",
        "    def saludo(self):\n",
        "        print(f\"Hola , Soy {self.nombre}, tu asistente de confianza para esta reunion y te ayudare con la generacion de  {self.acta}\")\n",
        "\n",
        "# Instanciamos\n",
        "AsistenteActas_principal = AsistenteActas(\"Claritsa\", \"ACTAS REUNIONES AL INSTANTE\")\n",
        "\n",
        "# Mostrar la presentación en pantalla\n",
        "AsistenteActas_principal.saludo()\n",
        "\n",
        "DatosEntrada = []\n",
        "print(\"📋Para comenzar, Ingrese los siguientes datos de la reunión:\")\n",
        "#nombre_proyecto = input(\"Nombre del proyecto:\")\n",
        "nombre_reunion = input(\"Nombre de la reunión: \")\n",
        "fecha = input(\"Fecha (ej. 2025-06-09): \")\n",
        "decisiones = input(\"Decisiones tomadas:(separadas por una :,) \")\n",
        "print(\"Dame un momento, generare el acta de tu reunion:\",DatosEntrada )\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3iiah_dT7vH",
        "outputId": "a1343f16-e350-4957-bf09-b82c8b00d8fb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola , Soy Claritsa, tu asistente de confianza para esta reunion y te ayudare con la generacion de  ACTAS REUNIONES AL INSTANTE\n",
            "📋Para comenzar, Ingrese los siguientes datos de la reunión:\n",
            "Nombre de la reunión: eliza\n",
            "Fecha (ej. 2025-06-09): 2025-06-09\n",
            "Decisiones tomadas:(separadas por una :,) ana lee, juan escribe\n",
            "Dame un momento, generare el acta de tu reunion: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generaciondelprompt\n",
        "prompt = \", \".join(DatosEntrada)\n",
        "\n",
        "# Conversacionparageneraracta\n",
        "conversation = [\n",
        "{\"role\": \"system\", \"content\": context},\n",
        "{\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "\n",
        "#ConversarconOpenIa\n",
        "response = client.chat.completions.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=conversation,\n",
        "max_tokens=500\n",
        ")\n",
        "\n",
        "# Imprimir respuesta\n",
        "print(\"\\n📝 Este es el acta de tu reunión:\")\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "OrtTBm6AeXiM",
        "outputId": "61f07af0-5b32-473c-e24d-a863d2882208"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: TU_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-3411593569>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#ConversarconOpenIa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconversation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: TU_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDvWTVywT9PD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WztxjK1QUBAO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O8bPybNHTQrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E7ERZc8lTUA6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nA0Oi_VuTRnm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z6QPNDgjTLwd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ez_1VF1oTPGZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cq0yxEztTPqH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vs8v9ewxRYd5"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}