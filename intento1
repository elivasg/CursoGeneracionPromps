{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjtObKQVCKtEFSYp4jaYSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elivasg/CursoGeneracionPromps/blob/main/Cursogeneracion_de_promps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjkphsH5Q4lO",
        "outputId": "0f9d7dc3-d20e-4ae9-96d7-de603d3277b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrega 2 Curso Generacion de Promps\n"
          ]
        }
      ],
      "source": [
        "print(\"Entrega 2 Curso Generacion de Promps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NR49X22BA-oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELIZABETH VASQUEZ GOMEZ\n",
        "IDEA ALQUIMICA : TEJIENDO EL FUTURO CON PROMP INGINEERING\n",
        "INTELIGENCIA ARTIFICIAL GENERACION DE PROMPS\n",
        "Comisi√≥n 84185 *texto en cursiva*\n",
        "ACTAS REUNIONES AL INSTANTE *texto en cursiva*\n",
        "\n",
        "**PRESENTACION DEL PROBLEMA:**\n",
        "Dentro de un proyecto de implementaci√≥n de software se tienen m√∫ltiples reuniones, t√©cnicas, t√°cticas y de planeaci√≥n donde se toman decisiones diariamente, est√°n se conversan, pero dadas las m√∫ltiples ocupaciones que tienen las personas nadie cuenta con el tiempo ni con la capacidad de generar un informe de la reuni√≥n con los pendientes y cada uno de sus responsables.\n",
        "Se desea generar a trav√©s de herramientas de inteligencia artificial , una soluci√≥n donde se pueda ingresar informaci√≥n clave de la reuni√≥n y este genere un informe estructurado y oficial sobre los temas de la reuni√≥n, decisiones, Compomisos\n",
        "Con los compromisos ingresados se generara una imagen infogr√°fica como parte del acta\n",
        "Datos de entrada:\n",
        "‚Ä¢\tProyecto :\n",
        "‚Ä¢\tNombre Reuni√≥n:\n",
        "‚Ä¢\tFecha:\n",
        "‚Ä¢\tDecisiones\n",
        "‚Ä¢\tCompomisos\n",
        "Salida:\n",
        "‚Ä¢\tActa en texto\n",
        "‚Ä¢\tImagen infogr√°fica con  resumen de la reuni√≥n de acuerdo a los datos dados y los compromisos\n",
        "\n",
        "\n",
        "**Importancia de desarrollar la soluci√≥n : **\n",
        "Esta actividad permitir√° tener a la mano, la informaci√≥n de todas las decisiones y acuerdos a los que se lleguen en las reuniones, para que se puedan guardar y cualquier persona consultarlo, eliminando  reprocesos y apoyando la gesti√≥n del conocimiento del equipo, sin tener que asignar esta tarea tediosa y de poca acogida a las personas del equipo.\n",
        "\n",
        "**Desarrollo de la propuesta a abordar:**\n",
        "Los modelos IA que se desean relacionar la desarrollo de esta propuesta son:\n",
        "Texto a texto : Al momento de ingresar los datos de entrada sobre la reuni√≥n . Chat GPT 3.5 ( ‚ÄúToma texto de entrada y genera texto como salida‚Äù) √≥ gemini\n",
        "Texto a Imagen: Para generar el resumen y la infograf√≠a de los compromisos.\n",
        "\n",
        "\n",
        "**Viabilidad t√©cnica del proyecto**\n",
        "El proyecto es viable, ya que con herramientas como OPEN IA y la adquisici√≥n de una Open Key , se puede usar el modelo GPT 3.5 para el texto a texto. En caso de no contar con el presupuesto, se explorario Gemini.\n",
        "Para la generaci√≥n de la imagen desea utilizar Dall-e\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_R4I-VIPBNc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6lFNShonA9P4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar compoentes requeridos\n",
        "import sys\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "import requests\n",
        "import os\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import csv\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "iPJzUcOuTYHf"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKO817jidI3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4QLw1z5bdJaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "d5iT5Ew5dsHv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creacion de contexto\n",
        "context = \"Eres la responsable de generar las notas, acuerdos y compromisos que se hacen en las reuniones de un equipo de desarrollo de software donde es muy importante que todo quede claro\"\n",
        "\n",
        "# saludo\n",
        "class AsistenteActas:\n",
        "    def __init__(self, nombre, acta):\n",
        "        self.nombre = nombre\n",
        "        self.acta = acta\n",
        "\n",
        "    def saludo(self):\n",
        "        print(f\"Hola , Soy {self.nombre}, tu asistente de confianza para esta reunion y te ayudare con la generacion de  {self.acta}\")\n",
        "\n",
        "# Instanciamos\n",
        "AsistenteActas_principal = AsistenteActas(\"Claritsa\", \"ACTAS REUNIONES AL INSTANTE\")\n",
        "\n",
        "# Mostrar la presentaci√≥n en pantalla\n",
        "AsistenteActas_principal.saludo()\n",
        "\n",
        "DatosEntrada = []\n",
        "print(\"üìãPara comenzar, Ingrese los siguientes datos de la reuni√≥n:\")\n",
        "#nombre_proyecto = input(\"Nombre del proyecto:\")\n",
        "nombre_reunion = input(\"Nombre de la reuni√≥n: \")\n",
        "fecha = input(\"Fecha (ej. 2025-06-09): \")\n",
        "decisiones = input(\"Decisiones tomadas:(separadas por una :,) \")\n",
        "print(\"Dame un momento, generare el acta de tu reunion:\",DatosEntrada )\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3iiah_dT7vH",
        "outputId": "a1343f16-e350-4957-bf09-b82c8b00d8fb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola , Soy Claritsa, tu asistente de confianza para esta reunion y te ayudare con la generacion de  ACTAS REUNIONES AL INSTANTE\n",
            "üìãPara comenzar, Ingrese los siguientes datos de la reuni√≥n:\n",
            "Nombre de la reuni√≥n: eliza\n",
            "Fecha (ej. 2025-06-09): 2025-06-09\n",
            "Decisiones tomadas:(separadas por una :,) ana lee, juan escribe\n",
            "Dame un momento, generare el acta de tu reunion: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generaciondelprompt\n",
        "prompt = \", \".join(DatosEntrada)\n",
        "\n",
        "# Conversacionparageneraracta\n",
        "conversation = [\n",
        "{\"role\": \"system\", \"content\": context},\n",
        "{\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "\n",
        "#ConversarconOpenIa\n",
        "response = client.chat.completions.create(\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=conversation,\n",
        "max_tokens=500\n",
        ")\n",
        "\n",
        "# Imprimir respuesta\n",
        "print(\"\\nüìù Este es el acta de tu reuni√≥n:\")\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "OrtTBm6AeXiM",
        "outputId": "61f07af0-5b32-473c-e24d-a863d2882208"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: TU_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-3411593569>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#ConversarconOpenIa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconversation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: TU_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDvWTVywT9PD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WztxjK1QUBAO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O8bPybNHTQrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E7ERZc8lTUA6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nA0Oi_VuTRnm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z6QPNDgjTLwd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ez_1VF1oTPGZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cq0yxEztTPqH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vs8v9ewxRYd5"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}
